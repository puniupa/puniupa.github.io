---
title: "LLM が真に社会に受け入れられるまで"
subtitle: "近年の発展のまとめ"
author: "ぷに"
date: 2/20/2024
categories: [AI, Disinformation]
bibliography: 
    - ../../../assets/mathematics.bib
    - ../../../assets/bib.bib
csl: ../../../assets/apalike.csl
shift-heading-level-by: -1
abstract: LLM が社会に大きな影響を与えたことは間違いないが，真に社会に溶け込み，社会の役に立ったり，既存の意思決定システムの一環を担えるようになるためには解決しなければいけない問題が多すぎる．本稿はそのうちいくつかをまとめる試みである．
---

## LLaMA の一般公開とその影響 {#sec-LLaMA}

Meta AI が [7/18/2023](https://about.fb.com/ja/news/2023/07/meta-and-microsoft-introduce-the-next-generation-of-llama/) に LLM [LLaMA](https://llama.meta.com/) [@Touvron+2023] を公開した．そして API を通じて利用する形ではなく，そのモデルのウェイトが公開されたため，Stanford 大学の [Alpaca](https://github.com/tatsu-lab/stanford_alpaca) など，モデルの改良と研究が促進されている．

特に事後調整のための公開データセットの整備が進んでおり，[Alpaca](https://github.com/tatsu-lab/stanford_alpaca) では Self-Instruct [@Wang+2023-Self-Instruct] による効率的な alignment 技術が採用されている．

産業界でも影響は大きい．[ELYZA](https://elyza.ai/) は [12/27/2023](https://elyza.ai/news/2023/12/27/130%E5%84%84%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%81%AE%E5%95%86%E7%94%A8%E5%88%A9%E7%94%A8%E5%8F%AF%E8%83%BD%E3%81%AA%E6%97%A5%E6%9C%AC%E8%AA%9Ellmelyza-j) に日本語に特化した LLM である ELYZA-japanese-Llama-2-13b を公開している．[Stockmark](https://stockmark.co.jp/) も [10/27/2023](https://stockmark.co.jp/news/20231027) に Stockmark-13b を公開している．

いずれも，開発費と開発時間が大幅に圧縮されたという．^[[日経新聞 (2/19/2024)](https://www.nikkei.com/article/DGXZQOUC268J80W3A221C2000000/)]

IBM は [9/12/2023](https://jp.newsroom.ibm.com/2023-09-12-Blog-Building-AI-for-business-IBM-Granite-foundation-models) に LLM Granite を発表している．加えて，プラットフォーム `watsonx` も提供しており，その上で RAG など独自の事後調整を可能にしている．

IBM と Meta の２社が発起人となり，[12/5/2023](https://www.ibm.com/blogs/solutions/jp-ja/the-ai-alliance/) に AI Alliance が発足し，オープンイノベーションを推進している．

[Stable Diffusion](https://ja.stability.ai/stable-diffusion) [@Rombach+2022] もソースコードとウェイトが [一般公開](https://github.com/Stability-AI/stablediffusion) されている．

## LLM の経済的影響

[@Tamkin+2021] は早い段階での OpenAI と Stanford 大学 [HAI](https://hai.stanford.edu/) (Human-centered AI) との対談録である．

OpenAI はコード生成能力の経済的な影響を重要なアジェンダとしている [@Manning+2022]．

Open AI の [Codex](https://openai.com/blog/openai-codex) [@Chen+2021] はプログラム言語を扱うトランスフォーマーであり，[GitHub Copilot](https://github.com/features/copilot) の元となっている．これが社会に与える影響も，新たな評価フレームワークと共に提案されている [@Khlaaf+2022]．

LLM の労働市場へのインパクトも推定している [@Eloundou+2023]．これによると，アメリカの労働者の 80% が，LLM の導入により少なくとも仕事の 10% に影響が生じるとしている．さらに全体の 20% は仕事の半分以上が影響を受けるとしている．

## 世界モデルとしての基盤モデル

### 社会行動シミュレーターとしての LLM

社会的なシミュレーションを LLM 内で行うことで，社会科学やビジネスの場面での意思決定を支援することが期待されている．

LLM は人間の心の理論を理解し，その心情・意図を（ある程度）シミュレートすることが出来るようである [@Andreas2022]．

LLM でのシミュレーションを通じて，社会科学的な知識を引き出そうとする試みもある [@Leng-Yuan2023]．

## LLM と経済安全保障

### 幻覚の防止

LLM が事実と異なる物語を生成することを **幻覚** (hallucination) と呼び，一部の応用では問題になることがある．

これを解決するにあたって，**等角推測** (conformal prediction) と組み合わせ，出力の不確実性を評価することで幻覚を防止する手法が提案されている [@Mohri-Hashimoto2024]．

一般に意思決定の場面において AI を活用するには，不確実性の定量化が必要不可欠である．

GPT-3 を Bayesian にし，自身の確証度合いを言表するように事後調整する研究が OpenAI で行われている [@Lin+2022]．

### ウォーターマーク

ウォーターマークを開発することで，LLM から出力された文章であることを高確率で検出できるようにする方法が，統計的仮説検定の技術を応用して提案されている [@Kuditipudi+2023]．

### 偽情報対策

生成 AI は，一国の政府が特定のプロパガンダを流布するための効果的な手段として選ばれることになる．その際の考え得る使用例と，それに対する対策が考えられてる [@Goldstein+2023]．

特に，2022 年に始まったロシアによるウクライナ侵攻は，最初の本格的な AI による情報戦と認識されつつある [@Sobchuk2024]．

これに対する対抗手段として，ウクライナのスタートアップ [Osavul](https://www.osavul.cloud/) や [Mantis Analytics](https://mantisanalytics.com/) によって使われているのもやはり LLM である．

[![Mantis Analytics の製品のデモ（クリックで URL を開く）](../../../static/Files/MantisAnalytics.png)](https://mantisanalytics.com/)

### 開発規制

[@Anderljung+2023] は先端的な AI を [Frontier AI](https://www.cnas.org/publications/commentary/frontier-ai-regulation-managing-emerging-risks-to-public-safety) と呼び，これの開発過程におけるあるべき規制を模索している．監督当局に執行権を付与することやフロンティアAIモデルのライセンス制度などが議論されている．

[@Shoker+2023] は LLM と国家安全保障との関係を議論している．信頼構築措置 (CBMs: Confidence-Building Measures) とは，国家間の敵意を減少させることで，衝突のリスクを減らす措置の全般をいう．元々は冷戦時代に提案された概念であるが，これを LLM 開発に適用することが具体的に提案されている．

### 生物学的脅威

LLM の登場により個人がエンパワーメントを受けており，生物学的脅威を作る障壁が低下していることは間違いない．

[@Patwardhan+2024] では，生物学的リスクに焦点を当てて，AI による安全リスク評価の手法と事前警鐘システムを模索している．この研究では，LLM によりリスクが増加するという統計的に有意義な証拠は得られていないが，この方面の研究の草分けとなっている．

## アラインメント問題

## 文献紹介 {.appendix}

大規模言語モデルとトランスフォーマーに関するより詳しい内容は，次の記事も参照：

```{=html}
<div class="article-card-container">
    <div class="article-card">
        <a href="https://162348.github.io/posts/2024/Kernels/Deep2.html" target="_blank">
            <img src="https://162348.github.io/posts/2024/Kernels/Transformer_cut.png" alt="Article Image" class="article-image">
            <div class="article-content">
                <h3 class="article-title">トランスフォーマー（深層生成モデル１）</h3>
                <p class="article-description">2023 年までの「基盤モデル」と呼ばれるような大規模な深層学習モデルは，ほとんど全て同一のアーキテクチャを持つ．これがトランスフォーマーである．その構造を，主に言語の分野に注目して概説する．最後に画像と動画の分野にも触れる．</p>
            </div>
        </a>
    </div>
</div>
```